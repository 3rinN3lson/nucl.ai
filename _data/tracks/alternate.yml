- title: Data Processing for Novel Input Devices
  description: >
    <p>Devices like the Kinect v2, Tango and FaceWare Live allow new possibilities for user input. We are working on several plugins for Unreal Engine 4 that make use of data provided by this equipment.  Since they are based on  image recognition and machine learning, one of the biggest challenges in working with these devices is that they occasionally provide unstable, undefined, unpredictable or outright unusable data.<p>
    <p>In this talk we will discuss the following (based on demos shown in the nucl.ai labs):</p>
    <ul>
    <li>the common types and formats of data presented by these devices,</li>
    <li>the pre-processing these devices tend to do on their data,</li>
    <li>the methods we use to sanitize and sanity-check the data we make available to developers,</li>
    <li>techniques we’re currently experimenting with as well as those we discarded,</li>
    <li>how this data has been used in applications</li>
    </ul>
  speakers:
    - Chris Mackenzie
    - Vikram Saran
  room: amphitheatre
  time:
    start: "14:00"
    finish: "14:45"

- title: "Multi-Kinect Motion Tracking and Interactive Installations"
  description: >
    <p>What goes into creating a multi-user multi-Kinect interactive installation to convey a somewhat abstract message, other than blood, sweat, and a lot of development time?</p>
    <p>I’ll discuss the process, our use of both open-source and off-the-shelf AI libraries, as well as when we roll our own. I’ll go over the challenges of building them, with a distributed team, with fuzzy design requirements to convey even fuzzier concepts, and against fixed and very tight deadlines.</p>
  speakers:
    - Ricardo J. Méndez
  room: masterclass
  time:
    start: "12:00"
    finish: "12:45"

- title: "Insights into the Next User Interfaces & Devices (Expert Panel)"
  description: >
    <p>Look beyond gamepads and keyboards in this group discussion among all the day's
    speakers will try to find common ground about problems with existing devices, the best
    user interfaces available now, and what are the most promising ones for future games and
    interactive applications.</p>
    <p>Topics will include vision-based approaches vs. depth-based cameras, single vs. multiple
    trackers, as well as insights how these impact design.  Questions from the audience are
    very welcome for all the speakers!</p>
  speakers:
    - Ricardo J. Méndez
    - Vikram Saran
    - Richard Kogelnig
    - Alex J. Champandard
  room: masterclass
  time:
    start: "16:45"
    finish: "17:30"

- title: "Living-Room Augmented Reality and Project Trains"
  description: >
    <p>As goggle-based AR slowly matures, there's a window of opportunity for projector-based AR experiences.  It's also a great way to learn about the technology and the impacts on design required to pull off augmented reality in practice &mdash; with a setup that works reliably now already!</p>
    <p>This short tutorial about <a href="http://project-trains.tumblr.com/">Project Trains</a> will show some of the biggest lessons learned from building an interactive living room experience from two kids, from the computer vision aspect to the crafting (litterally) of a projector-based experience with augmented toy tracks.</p>
  speakers:
    - Alex J. Champandard
  room: masterclass
  time:
    start: "16:15"
    finish: "16:45"

- title: Object Recognition with Neural Networks (Workshop)
  description: >
    <p>This workshop is a tutorial for recognizing images of objects with modern neural networks.  You'll use open-source libraries and get up-to-speed with Deep Learning, understanding how to apply deep neural networks in practice as both classifiers (to predict labels from input features) or regressors (to predict an output based on inputs).</p>
    <p>This hands-on tutarial will show you how to get up and running on your own laptop, how to train neural networks and adjust their parameters, and how to "augment" input datasets for better results.  You'll see how this works in code, at your own pace, and with help and advice from the authors of a popular open-source library.</p>  
  room: laboratories
  speakers:
    - Spyridon Samothrakis
  time:
    start: "9:45"
    finish: "12:00"

- title: Hardware Demo Time in the Conference Lobby!
  description: >
    Try out a variety of devices from input sensors and headsets, as well as a demo for the previous talk using Kinects.
    Also throw fireballs in a magical fairyland brought into life by Leap Motion Hand Tracking and the Oculus Rift (DK2).  Get your hands on the Rift, Hydra, Leap Motion and other devices and experience what VR is about!
  room: laboratories
  speakers:
    - Richard Kogelnig
    - Chris Mackenzie
    - Vikram Saran
  time:
    start: "14:45"
    finish: "15:45"
